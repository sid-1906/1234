{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Federated Learning in Blockchain for Data Privacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Names: ['Transaction 1', 'Transaction 2', 'Transaction 3', 'Transaction 4', 'Transaction 5']\n",
      "Transaction ID: [98942, 31938, 51234, 87906, 67813]\n",
      "Labels: ['Correct', 'Anomaly', 'Correct', 'Anomaly', 'Correct']\n",
      "************************** All block details ****************************\n",
      "Name: Transaction 1\n",
      "Transaction ID: 98942\n",
      "Label: Correct\n",
      "Timestamp: 1697861909\n",
      "Hash: 9b95421c346be3a755a4a1a6ae3e715f8686be2f2bd6d3f7769f924c9fa78737\n",
      "\n",
      "Name: Transaction 2\n",
      "Transaction ID: 31938\n",
      "Label: 1\n",
      "Timestamp: 1697861909\n",
      "Hash: 5bbacdc02636adba1b3933eb42c0f0249b6c682e91b146f5fddfff41a1426836\n",
      "\n",
      "Name: Transaction 3\n",
      "Transaction ID: 51234\n",
      "Label: 1\n",
      "Timestamp: 1697861909\n",
      "Hash: 3c06602f3056578d0958070cfab905c7ea508992ab2d05af2e44cc1026aa4279\n",
      "\n",
      "Name: Transaction 4\n",
      "Transaction ID: 87906\n",
      "Label: 1\n",
      "Timestamp: 1697861909\n",
      "Hash: b218ea0756b6a70ec677ac60fc9d2d12676928bdeb2f9c4de7badd521dfdb7e3\n",
      "\n",
      "Name: Transaction 5\n",
      "Transaction ID: 67813\n",
      "Label: 1\n",
      "Timestamp: 1697861909\n",
      "Hash: 3de68e24e6d156e75238520c654addbbfa68f058446022cbe7137dec3debe57f\n",
      "\n",
      "******************************** remote_transactions ********************************\n",
      "Transaction 1: {'transaction_id': 98942, 'label': 'Correct'}\n",
      "Transaction 2: {'transaction_id': 31938, 'label': 'Anomaly'}\n",
      "Transaction 3: {'transaction_id': 51234, 'label': 'Correct'}\n",
      "Transaction 4: {'transaction_id': 87906, 'label': 'Anomaly'}\n",
      "Transaction 5: {'transaction_id': 67813, 'label': 'Correct'}\n",
      "******************************** datasets values ***********************************\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import namegenerator\n",
    "import hashlib as hasher\n",
    "import torch\n",
    "import random\n",
    "import time\n",
    "# Creating list for names of a transactions\n",
    "names = [\"Transaction 1\", \"Transaction 2\", \"Transaction 3\", \"Transaction 4\", \"Transaction 5\"]\n",
    "\n",
    "# Creating list for tranasaction_id\n",
    "transaction = [random.randint(10000, 99999) for i in range(len(names))]\n",
    "\n",
    "# Labels for each each transaction either it was anamoly or correct\n",
    "labels = [\"Correct\", \"Anomaly\", \"Correct\", \"Anomaly\", \"Correct\"]\n",
    "\n",
    "# Printing the results\n",
    "print(\"Names:\", names)\n",
    "print(\"Transaction ID:\", transaction)\n",
    "print(\"Labels:\", labels)\n",
    "\n",
    "def create_genesis_block():\n",
    "  \"\"\"Creates the genesis block.\"\"\"\n",
    "  timestamp = int(time.time())\n",
    "  return Block(names[0], transaction[0], labels[0], timestamp)\n",
    "\n",
    "def next_block(last_block, j):\n",
    "  \"\"\"Creates a new block.\"\"\"\n",
    "  timestamp = int(time.time())\n",
    "  this_name = names[j]\n",
    "  this_transaction_id = transaction[j]\n",
    "  this_label = labels[j]\n",
    "  this_hash = last_block.hash\n",
    "  return Block(this_name, this_transaction_id, label, timestamp, this_hash)\n",
    "\n",
    "class Block:\n",
    "  \"\"\"A block in the blockchain.\"\"\"\n",
    "\n",
    "  def __init__(self, name, transaction_id, label, timestamp, previous_hash=None):\n",
    "    self.name = name\n",
    "    self.transaction_id = transaction_id\n",
    "    self.label = label\n",
    "    self.timestamp = timestamp\n",
    "    self.previous_hash = previous_hash\n",
    "    self.hash = self.hash_block()\n",
    "\n",
    "  def hash_block(self):\n",
    "    \"\"\"Computes the hash of the block.\"\"\"\n",
    "    sha = hasher.sha256()\n",
    "    sha.update(str(self.name).encode('utf-8') +\n",
    "               str(self.transaction_id).encode('utf-8') +\n",
    "               str(self.label).encode('utf-8') +\n",
    "               str(self.timestamp).encode('utf-8') +\n",
    "               str(self.previous_hash).encode('utf-8'))\n",
    "    return sha.hexdigest()\n",
    "\n",
    "# Create the blockchain\n",
    "blockchain = [create_genesis_block()]\n",
    "previous_block = blockchain[0]\n",
    "num_of_blocks_to_add = len(names)\n",
    "\n",
    "# Add blocks to the blockchain\n",
    "for i in range(1, num_of_blocks_to_add):\n",
    "  block_to_add = next_block(previous_block, i)\n",
    "  blockchain.append(block_to_add)\n",
    "  previous_block = block_to_add\n",
    "\n",
    "# Print the blockchain\n",
    "print(\"************************** All block details ****************************\")\n",
    "for block in blockchain:\n",
    "  print(f\"Name: {block.name}\")\n",
    "  print(f\"Transaction ID: {block.transaction_id}\")\n",
    "  print(f\"Label: {block.label}\")\n",
    "  print(f\"Timestamp: {block.timestamp}\")\n",
    "  print(f\"Hash: {block.hash}\")\n",
    "  print()\n",
    "\n",
    "# Creating a dictionary to store the remote transactions\n",
    "remote_transactions = {}\n",
    "\n",
    "# Setting each transaction to remote\n",
    "for i in range(len(names)):\n",
    "  remote_transactions[names[i]] = {\n",
    "    \"transaction_id\": transaction[i],\n",
    "    \"label\": labels[i]\n",
    "  }\n",
    "\n",
    "# Printing the remote transactions\n",
    "print(\"******************************** remote_transactions ********************************\")\n",
    "for key, value in remote_transactions.items():\n",
    "  print(f\"{key}: {value}\")\n",
    "\n",
    "# Creating a list of datasets\n",
    "datasets = []\n",
    "\n",
    "# Adding a check to make sure that the transaction ID and label are both present in the dataset\n",
    "for i in range(len(names)):\n",
    "  if names[i] in remote_transactions and transaction[i] in remote_transactions:\n",
    "    datasets.append((names[i], remote_transactions[names[i]]))\n",
    "\n",
    "# Printing the datasets\n",
    "print(\"******************************** datasets values ***********************************\")\n",
    "for dataset in datasets:\n",
    "  print(dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import random\n",
    "import namegenerator\n",
    "import hashlib as hasher\n",
    "import time\n",
    "\n",
    "from torch import nn\n",
    "from torch import optim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(iterations = 20):\n",
    "  model = nn.Linear(50,22)\n",
    "  optimizer_fed = optim.SGD(params = model.parameters(), lr = 0.1)\n",
    "  for iter in range(iterations):\n",
    "    for data, target in datasets:\n",
    "      model = model.send(data.location)\n",
    "      optimizer_fed.zero_grad()\n",
    "      pred = model(data)\n",
    "      loss = (( pred - target) ** 2).sum()\n",
    "      loss.backward()\n",
    "      optimizer_fed.step()\n",
    "      model = model.get()\n",
    "      print(loss.get())\n",
    "      #torch.save(model.state_dict(), \"model.pt\")\n",
    "\n",
    "      \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "model = nn.Linear(50, 22)\n",
    "\n",
    "def train(iterations = 20):\n",
    "  model = nn.Linear(50,22)\n",
    "  optimizer_fed = optim.SGD(params = model.parameters(), lr = 0.1)\n",
    "  for iter in range(iterations):\n",
    "    for data, target in datasets:\n",
    "      model = model.send(data.location)\n",
    "      optimizer_fed.zero_grad()\n",
    "      pred = model(data)\n",
    "      loss = (( pred - target) ** 2).sum()\n",
    "      loss.backward()\n",
    "      optimizer_fed.step()\n",
    "      model = model.get()\n",
    "      print(loss.get())\n",
    "      #torch.save(model.state_dict(), \"model.pt\")\n",
    "\n",
    "# Save the trained model\n",
    "torch.save(model.state_dict(), \"model.pt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = nn.Linear(50, 22)\n",
    "model.load_state_dict(torch.load(\"model.pt\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.6978,  0.4367, -0.8118,  0.1862,  0.0659,  0.2834,  0.0105,  0.0184,\n",
      "          0.0438, -1.1972, -0.1141,  0.3335,  0.0969, -0.3249,  0.7084, -0.2961,\n",
      "          0.0245, -0.4710, -0.3482,  0.2798,  0.9593,  0.8677]],\n",
      "       grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Create a new dataset\n",
    "new_data = torch.randn((1, 50))\n",
    "\n",
    "# Make a prediction\n",
    "prediction = model(new_data)\n",
    "\n",
    "# Print the prediction\n",
    "print(prediction)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
